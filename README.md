# AI & ML Projects

This repository contains a collection of my AI and ML projects that I have completed during my studies. Each project is represented by an IPython Notebook file (.ipynb), showcasing different techniques and algorithms.

## Project 1 : Supervised Learning

The "Supervised Learning Project" demonstrates my skills in applying supervised learning algorithms to solve a specific problem. The notebook includes data preprocessing, feature engineering, model training, evaluation, and result analysis.

<h2 align="center"><strong>Part - A</strong></h2>

**DOMAIN**: Medical

**CONTEXT**: Develop an AI/ML model for medical research to predict patient conditions based on biomechanics features without revealing patient details due to confidentiality.

**DATA DESCRIPTION**: Biomechanics features of patients are represented by six attributes, including pelvic tilt, lumbar lordosis angle, sacral slope, pelvic incidence, pelvic radius, and spondylolisthesis degree.

**PROJECT OBJECTIVE**: Train Supervised Learning algorithms to predict patient conditions using the provided biomechanics data.

**Technologies & Tools Used:**
- Python
- pandas
- numpy
- matplotlib
- seaborn
- Jupyter Notebook
- scikit-learn
- Hyperparameter-tuning
- Grid search
- Randomized Search CV
- KNN

<h2 align="center"><strong>Part - B</strong></h2>

**DOMAIN**: Banking, Marketing

**CONTEXT**: Implement Machine Learning to improve marketing campaigns in a growing bank by predicting potential customers who will convert based on historical data.

**DATA DESCRIPTION**: The dataset includes customer attributes like age, customer since, highest spend, zip code, hidden score, monthly average spend, level, mortgage, security, fixed deposit account, internet banking, credit card, and loan on a card.

**PROJECT OBJECTIVE**: Build an ML model for targeted marketing to increase conversion ratio and expand the borrower base with the same budget.

**Technologies & Tools Used:**
- Python
- pandas
- numpy
- matplotlib
- seaborn
- Jupyter Notebook
- scikit-learn
- Hyperparameter-tuning
- Grid search
- Randomized Search CV
- KNN
- SVM
- SMOTE

## Project 2: Ensemble Techniques

This repository showcases my project on Ensemble Techniques, where I explored various methods like Random Forest, AdaBoost, Gradient Boosting, Grid Search. The project uses real-world data to predict customer churn behavior in a telecom company, demonstrating the effectiveness of ensemble methods in improving machine learning model performance.

**DOMAIN:** Telecommunications.

**CONTEXT:** A telecom company wants to use their historical customer data and leverage machine learning to predict behavior in an attempt to retain customers. The end goal is to develop focused customer retention programs.

**DATA DESCRIPTION:** The dataset is relevant for understanding customer churn behavior and predicting customer churn. Analyzing customer churn is important for businesses to identify factors that contribute to customer attrition and develop strategies to retain customers.

**PROJECT OBJECTIVE**: The objective, as a data scientist hired by the telecom company, is to build a model that will help to identify the potential customers who have a higher probability to churn. This will help the company to understand the pain points and patterns of customer churn and will increase the focus on strategising customer retention.

**Technologies & Tools Used:**
- Python
- pandas
- numpy
- matplotlib
- seaborn
- Jupyter Notebook
- scikit-learn
- Hyperparameter-tuning
- Grid search
- RandomForestClassifier
- AdaBoostClassifier
- GradientBoostingClassifier
- DecisionTreeClassifier

## Project 3: Unsupervised Learning

Welcome to my Unsupervised Learning Project, where I explore and analyze a dataset containing information about various vehicle attributes. In this project, I perform data preprocessing, exploration, clustering, and dimensionality reduction techniques to gain insights from the data.

### **Project Overview**

This project focuses on the following key aspects:

- **Data Exploration**: I start by loading and examining the dataset, understanding its structure, and performing basic exploratory data analysis (EDA) to get insights into the data's features and characteristics.
- **Data Cleaning and Preprocessing**: I handle missing values, identify outliers, and convert data types as necessary. I also perform data scaling to ensure uniformity across the dataset's numerical features.
- **Clustering Analysis**: Using K-means clustering, I identify patterns and groupings within the dataset based on the attributes of the vehicles. I determine the optimal number of clusters using techniques such as the elbow method and silhouette analysis.
- **Dimensionality Reduction**: I apply Principal Component Analysis (PCA) to reduce the dimensionality of the dataset while retaining relevant information. This helps visualize the data in a lower-dimensional space.
- **Model Training and Evaluation**: I train Support Vector Machine (SVM) models on both the original data and the reduced PCA components. I evaluate the models using classification metrics and analyze their performance.



## Contact

Feel free to connect with me on LinkedIn if you have any questions or would like to discuss my projects further:

https://www.linkedin.com/in/parin-parmar-0b9700200/

### PS: I will be working on various projects ahead and will keep updating the repository accordingly.
